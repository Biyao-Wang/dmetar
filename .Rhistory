#Plot the dots
plot(0:(k-1),var,xlab="",ylab="",type="b",yaxt="n",xaxt="n",main="",
cex.main=1.15,ylim=c(0,1),col=col)
#Add marker in results with 0 drops
points(0,var[1],pch=19,cex=1.6)
#Red line at p=.05
abline(h=.05,col="red")
#Y-axis value labels
axis(2,c(.05,2:9/10),labels=c('.05','.2','.3','.4','.5','6','7','.8','.9'),las=1,cex.axis=1.5)
axis(1,c(0:(k-1)),las=1,cex.axis=1.4)
}
######################################################################################
# 9. Effect Estimation ###############################################################
######################################################################################
if (effect.estimation == TRUE){
# Define ci.to.t function
ci.to.t = function(TE, lower, upper, n){
z.to.d = function(z, n){
d = (2*z)/sqrt(n)
return(abs(d))
}
ci.to.p = function(est, lower, upper){
SE = (upper-lower)/(2*1.96)
z = abs(est/SE)
p = exp(-0.717*z - 0.416*z^2)
return(p)
}
d.to.t = function(d, n){
df = n-2
t = (d*sqrt(df))/2
return(t)
}
p = ci.to.p(TE, lower, upper)
z = abs(qnorm(p/2))
d = z.to.d(z, n)
t = d.to.t(d, n)
return(t)
}
#Function 13 - loss function
loss=function(t_obs,df_obs,d_est) {
#1.Convert all ts to the same sign (for justification see Supplement 5)
t_obs=abs(t_obs)
#2 Compute p-values
p_obs=2*(1-pt(t_obs,df=df_obs))
#3 Keep significant t-values and corresponding df.
t.sig=subset(t_obs,p_obs<.05)
df.sig=subset(df_obs,p_obs<.05)
#4.Compute non-centrality parameter implied by d_est and df_obs
#df+2 is total N.
#Becuase the noncentrality parameter for the student distribution is ncp=sqrt(n/2)*d,
#we add 2 to d.f. to get N,  divide by 2 to get n, and by 2 again for ncp, so -->df+2/4
ncp_est=sqrt((df.sig+2)/4)*d_est
#5.Find critical t-value for p=.05 (two-sided)
#this is used below to compute power, it is a vector as different tests have different dfs
#and hence different critical values
tc=qt(.975,df.sig)
#4.Find power for ncp given tc, again, this is a vector of implied power, for ncp_est,  for each test
power_est=1-pt(tc,df.sig,ncp_est)
#5.Compute pp-values
#5.1 First get the overall probability of a t>tobs, given ncp
p_larger=pt(t.sig,df=df.sig,ncp=ncp_est)
#5.2 Now, condition on p<.05
ppr=(p_larger-(1-power_est))/power_est  #this is the pp-value for right-skew
#6. Compute the gap between the distribution of observed pp-values and a uniform distribution 0,1
KSD=ks.test(ppr,punif)$statistic        #this is the D statistic outputted by the KS test against uniform
return(KSD)
}
if(missing(N)){
stop("If 'effect.estimation=TRUE', argument 'N' must be provided.")
}
if (length(N) != length(metaobject$TE)){
stop("N must be of same length as the number of studies contained in x.")
}
lower = metaobject$TE - (metaobject$seTE*1.96)
upper = metaobject$TE + (metaobject$seTE*1.96)
t_obs = ci.to.t(metaobject$TE, lower, upper, N)
df_obs = N-2
#Results will be stored in these vectors, create them first
loss.all=c()
di=c()
#Compute loss for effect sizes between d=c(dmin,dmax) in steps of .01
for (i in 0:((dmax-dmin)*100))
{
d=dmin+i/100                   #effect size being considered
di=c(di,d)                     #add it to the vector (kind of silly, but kept for symmetry)
options(warn=-1)               #turn off warning becuase R does not like its own pt() function!
loss.all=c(loss.all,loss(df_obs=df_obs,t_obs=t_obs,d_est=d))
#apply loss function so that effect size, store result
options(warn=0)                #turn warnings back on
}
#find the effect leading to smallest loss in that set, that becomes the starting point in the optimize command
imin=match(min(loss.all),loss.all)       #which i tested effect size lead to the overall minimum?
dstart=dmin+imin/100                     #convert that i into a d.
#optimize around the global minimum
dhat=optimize(loss,c(dstart-.1,dstart+.1), df_obs=df_obs,t_obs=t_obs)
options(warn=-0)
#Plot results
plot(di,loss.all,xlab="Effect size\nCohen-d", ylab="Loss (D stat in KS test)",ylim=c(0,1), main="How well does each effect size fit? (lower is better)")
points(dhat$minimum,dhat$objective,pch=19,col="red",cex=2)
text(dhat$minimum,dhat$objective-.08,paste0("p-curve's estimate of effect size:\nd=",round(dhat$minimum,3)),col="red")
}
######################################################################################
# 10. Prepare Results for Return #####################################################
######################################################################################
# Get results
main.results = round(main.results, 3)
ktotal = round(main.results[1]) # Get the total number of inserted TEs
k.sign = round(main.results[2]) # Get the total number of significant TEs
k.025 =  round(main.results[3]) # Get the number of p<0.25 TEs
skew.full.z = main.results[4] # Get the Z-score for the full curve skewness test
skew.full.p = main.results[5] # Get the p-value for the full curve skewness test
flat.full.z = main.results[6] # Get the Z-score for the full curve flatness test
flat.full.p = main.results[7] # Get the p-value for the full curve flatness test
skew.half.z = main.results[8] # Get the Z-score for the half curve skewness test
skew.half.p = main.results[9] # Get the p-value for the half curve skewness test
flat.half.z = main.results[10] # Get the Z-score for the half curve flatness test
flat.half.p = main.results[11] # Get the p-value for the half curve flatness test
skew.binomial.p = round(binomial[3], 3) # Get the skewness binomial p-value
flat.binomial.p = round(binomial[4], 3) # Get the flatness binomial p-value
# Make data.frame
skewness = c(skew.binomial.p, skew.full.z, skew.full.p, skew.half.z, skew.half.p)
flatness = c(flat.binomial.p, flat.full.z, flat.full.p, flat.half.z, flat.half.p)
colnames.df = c("pBinomial", "zFull", "pFull", "zHalf", "pHalf")
rownames.df = c("Right-skewness test", "Flatness test")
pcurveResults = rbind(skewness, flatness)
colnames(pcurveResults) = colnames.df
rownames(pcurveResults) = rownames.df
# Power results
power_results = round(power_results, 3)
powerEstimate = power_results[2]
powerLower = power_results[1]
powerUpper = power_results[3]
Power = as.data.frame(cbind(powerEstimate, powerLower, powerUpper))
rownames(Power) = ""
# Presence and absence of evidential value
# - If the half p-curve test is right-skewed with p<.05 or both the half and full test
#   are right-skewed with p<.1, then p-curve analysis indicates the presence of evidential value
# - Evidential value is inadequate or absent if the 33% power test is p<.05 for the full p-curve
#   or both the half p-curve and binomial 33% power test are p<.1
if (skew.half.p < 0.05 | (skew.half.p < 0.1 & skew.full.p < 0.1)){
presence.ev = "yes"
} else {
presence.ev = "no"
}
if (flat.full.p < 0.05 | (flat.half.p < 0.1 & flat.binomial.p < 0.1)){
absence.ev = "yes"
} else {
absence.ev = "no"
}
# Plot Data
PlotData = round(table_figure, 3)
# Input Data
table_calc[,1] = NULL
colnames(table_calc) = c("p", "ppSkewFull", "ppSkewHalf", "ppFlatFull", "ppFlatHalf", "zSkewFull", "zSkewHalf",
"zFlatFull", "zFlatHalf")
Input = cbind(metaobject$TE, round(table_calc,3))
rownames(Input) = paste(1:length(metaobject$TE), metaobject$studlab)
colnames(Input)[1] = "TE"
# Cat the results
cat("P-curve analysis", "\n", "-----------------------", "\n")
cat("- Total number of provided studies: k =", ktot, "\n")
cat("- Total number of p<0.05 studies included into the analysis: k =",
k.sign, paste("(", round(k.sign/ktot*100, 2), "%)", sep=""), "\n")
cat("- Total number of studies with p<0.025: k =", k.025,
paste("(", round(k.025/ktot*100, 2), "%)", sep=""), "\n")
cat("  ", "\n")
cat("Results", "\n", "-----------------------", "\n")
print(pcurveResults)
cat("Note: p-values of 0 or 1 correspond to p<0.001 and p>0.999, respectively.")
cat("  ", "\n")
cat("Power Estimate: ", Power[,1]*100, "%", " (", Power[,2]*100, "%-", Power[,3]*100, "%)", "\n",sep="")
cat("  ", "\n")
cat("Evidential value", "\n", "-----------------------", "\n")
cat("- Evidential value present:", presence.ev, "\n")
cat("- Evidential value absent/inadequate:", absence.ev, "\n")
if (effect.estimation==TRUE){
cat("  ", "\n")
cat("P-curve's estimate of the true effect size: d=", round(dhat$minimum, 3), sep="")
if (metaobject$I2 > 0.49 & (class(metaobject)[1] %in% c("metagen", "metabin", "metacont", "meta", "metainc"))){
cat("  ", "\n")
cat("Warning: I-squared of the meta-analysis is >= 50%, so effect size estimates are not trustworthy.")
}
dEstimate = round(dhat$minimum, 3)
return.list = list("pcurveResults" = pcurveResults,
"Power" = Power,
"PlotData" = PlotData,
"Input" = Input,
"EvidencePresent" = presence.ev,
"EvidenceAbsent" = absence.ev,
"kInput" = ktot,
"kAnalyzed" = k.sign,
"kp0.25" = k.025,
"dEstimate" = dEstimate)
} else {
return.list = list("pcurveResults" = pcurveResults,
"Power" = Power,
"PlotData" = PlotData,
"Input" = Input,
"EvidencePresent" = presence.ev,
"EvidenceAbsent" = absence.ev,
"kInput" = ktot,
"kAnalyzed" = k.sign,
"kp0.25" = k.025)
}
cat("  ", "\n")
invisible(return.list)
}
devtools::check(manual = TRUE)
devtools::build_manual()
devtools::load_all()
devtools::document()
devtools::load_all()
devtools::load_all()
library(dmetar)
?dmetar
devtools::build_vignettes()
devtools::build_vignettes(vignettes/dmetar.Rmd)
devtools::build_vignettes("vignettes/dmetar.Rmd")
devtools::build_vignettes("vignettes")
usethis::use_vignette("my-vignette")
devtools::build_vignettes()
devtools::build_vignettes()
devtools::clean_vignettes()
devtools::build_vignettes()
devtools::document()
devtools::check(manual = TRUE)
devtools::build_vignettes()
devtools::build_vignettes()
browseVignettes("dmetar")
pkgdown::build_site()
devtools::document()
pkgdown::build_site()
browseVignettes("dmetar")
devtools::check(manual = TRUE)
warnPartialMatchDollar
?warnPartialMatchDollar
options(warnPartialMatchDollar=FALSE)
devtools::check(manual = TRUE)
devtools::check(manual = TRUE)
devtools::check(manual = TRUE)
devtools::check(manual = TRUE)
devtools::document()
devtools::check(manual = TRUE)
?fixCoefNames
MuMIn:::reformulate
?reformulate
??fixCoefNames
MuMIn:::fixCoefNames()
MuMIn:::fixCoefNames
MuMIn:::fixCoefNames
MuMIn:::.getCoefNames()
MuMIn:::.getCoefNames
?rect
packageVersion("graphics")
packageVersion("stats")
devtools::document()
devtools::check(manual = TRUE)
?expr.split
MuMIn:::expr.split
?scale_y_continuous
?pbinom
coefTable.rma()
devtools::document()
devtools::check(manual = TRUE)
dmetar::NNT(0.38)
dmetar::NNT(0.3)
NNT(0.3)
d = NNT(0.3)
d
d = c(NNT(0.3), NNT(0.5), NNT(0.8))
d
devtools::check(manual = TRUE)
context("NNT checks")
library(dmetar)
test_that("Kraemer Kupfer method is correct", {
d = c(NNT(0.3), NNT(0.5), NNT(0.8))
expect_equal(d[1], 5.952524)
expect_equal(d[2], 3.618909)
expect_equal(d[3], 2.334309)
})
?expect_equal
d[1
d[1]
d[1]
5.952524
expect_equal(d[1], 5.952524)
test_that("Kraemer Kupfer method is correct", {
d = c(NNT(0.3), NNT(0.5), NNT(0.8))
expect_equal(round(d[1],3), round(5.952524,3))
expect_equal(round(d[2],3), round(3.618909,3))
expect_equal(round(d[3],3), round(2.334309,3))
})
devtools::check(manual = TRUE)
devtools::document()
pkgdown::build_site()
devtools::build_manual()
pkgdown::build_site()
pkgdown::build_articles()
pkgdown::build_articles()
knitr::opts_chunk$set(echo = TRUE)
getwd()
summary(cars)
<img src="fig/banner.jpg" align="left" alt="" width="500" />
pkgdown::build_articles()
pkgdown::build_articles()
pkgdown::build_articles()
library(dmetar)
pkgdown::build_articles()
library(meta)
pkgdown::build_articles()
pkgdown::build_articles()
pkgdown::build_articles()
data("ThirdWave")
data("MVRegressionData")
data("NetDataNetmeta")
nrow(ThirdWave)
?power.analysis
power.analysis(d = .19, k = 18, n1 = 50, n2 = 50, heterogeneity = "moderate")
power.analysis(d = .15, k = 18, n1 = 50, n2 = 50, heterogeneity = "moderate")
power.analysis(d = .17, k = 18, n1 = 50, n2 = 50, heterogeneity = "moderate")
power.analysis(d = .18, k = 18, n1 = 50, n2 = 50, heterogeneity = "moderate")
power.analysis(d = .18, k = 18, n1 = 50, n2 = 50, heterogeneity = "moderate")
pkgdown::build_articles()
?NNT
NNT(ThirdWave$TE[1], CER = 0.2)
?pool.grousp
?pool.groups
pool.groups(n1 = 50, n2 = 65, m1 = 12.3, m2 = 14.8, sd1 = 2.45, sd2 = 2.89)
?se.from.p
se.from.p(effect.size = 0.38, p = 0.0456, N = 83)
pkgdown::build_articles()
pkgdown::build_articles()
?rob.summary
data = data.frame(
"study" = c("Higgins et al., 2011", "Borenstein et al., 2008", "Holm, 1971",
"Zajonc et al., 2005", "Cuijpers, 2014"),
"Allocation_concealment" = c("Low", "High", "High", "Unclear", "High"),
"Randomization" = c("Low", "High", "Unclear", "Low", "High"),
"Sequence_generation" = c("Low", "High", "Unclear", "Unclear", "High"),
"ITT.Analyses" = c("Low", "High", "Unclear", "Unclear", "Unclear"),
"Selective_outcome_reporting" = c("Low", "High", "High", "High", "Unclear")
)
data = data.frame(
"study" = c("Higgins et al., 2011", "Borenstein et al., 2008", "Holm, 1971",
"Zajonc et al., 2005", "Cuijpers, 2014"),
"Allocation_concealment" = c("Low", "High", "High", "Unclear", "High"),
"Randomization" = c("Low", "High", "Unclear", "Low", "High"),
"Sequence_generation" = c("Low", "High", "Unclear", "Unclear", "High"),
"ITT.Analyses" = c("Low", "High", "Unclear", "Unclear", "Unclear"),
"Selective_outcome_reporting" = c("Low", "High", "High", "High", "Unclear")
)
rob.summary(data)
rob.summary(data, table = TRUE)
data
data = data.frame(
"study" = c("Higgins et al., 2011", "Borenstein et al., 2008", "Holm, 1971",
"Zajonc et al., 2005", "Cuijpers, 2014"),
"Allocation_concealment" = c("Low", "High", "High", "Unclear", "High"),
"Randomization" = c("Low", "High", "Unclear", "Low", "High"),
"Sequence_generation" = c("Low", "High", "Unclear", "Unclear", "High"),
"ITT.Analyses" = c("Low", "High", "Unclear", "Unclear", "Unclear"),
"Selective_outcome_reporting" = c("Low", "High", "High", "High", "Unclear")
)
studies = data$study
data = data[,2:5]
rob.summary(data, studies = studies, table = TRUE)
rob.summary(data, studies = studies, table = TRUE)
rob.summary(data, studies = studies, table = TRUE)
rob.summary(data, studies = studies, table = TRUE)
rob.summary(data, studies = studies, table = TRUE)
rob.summary(data, studies = studies, table = TRUE)
rob.summary(data, studies = studies, table = TRUE)
rs = rob.summary(data, studies = studies, table = TRUE)
rob.summary(data)
rob.summary(data)
rs = rob.summary(data, studies = studies, table = TRUE)
rob.summary(data, studies = studies, table = TRUE)
pkgdown::build_articles()
pkgdown::build_articles()
pkgdown::build_articles()
?subgroup.analysis.mixed.effects
?multimodel.inference
meta <- metagen(TE, seTE,
data = ThirdWave,
studlab = ThirdWave$Author,
comb.fixed = FALSE,
method.tau = "PM")
meta
subgroup.analysis.mixed.effects(x = meta, subgroups = ThirdWave$TypeControlGroup)
subgroup.analysis.mixed.effects(x = meta, subgroups = ThirdWave$TypeControlGroup, plot=FALSE)
subgroup.analysis.mixed.effects(x = meta, subgroups = ThirdWave$TypeControlGroup)
pkgdown::build_articles()
pkgdown::build_articles()
pkgdown::build_articles()
knitr::include_graphics("fig/rob_table.png")
pkgdown::build_articles()
?multimodel.inference
multimodel.inference(TE = 'yi', seTE = 'sei', data = MVRegressionData,
predictors = c('pubyear', 'quality',
'reputation', 'continent'))
multimodel.inference(TE = 'yi', seTE = 'sei', data = MVRegressionData,
predictors = c('pubyear', 'quality',
'reputation', 'continent'))
pkgdown::build_articles()
View(coefTable.rma)
View(makeArgs.rma)
View(multimodel.inference)
pkgdown::build_articles()
pkgdown::build_articles()
library(knitr)
hook_output <- knit_hooks$get("output")
knit_hooks$set(output = function(x, options) {
lines <- options$output.lines
if (is.null(lines)) {
return(hook_output(x, options))  # pass to default hook
}
x <- unlist(strsplit(x, "\n"))
more <- "..."
if (length(lines)==1) {        # first n lines
if (length(x) > lines) {
# truncate the output, but add ....
x <- c(head(x, lines), more)
}
} else {
x <- c(more, x[lines], more)
}
# paste these lines together
x <- paste(c(x, ""), collapse = "\n")
hook_output(x, options)
})
pkgdown::build_articles()
multimodel.inference(TE = 'yi', seTE = 'sei', data = MVRegressionData,
predictors = c('pubyear', 'quality',
'reputation', 'continent'))
pkgdown::build_articles()
pkgdown::build_articles()
InfluenceAnalysis(meta)
InfluenceAnalysis(meta)
pkgdown::build_articles()
pkgdown::build_articles()
meta$comb.fixed
eggers.test(meta)
pcurve(meta)
pcurve(meta)
pkgdown::build_articles()
pkgdown::build_articles()
pkgdown::build_articles()
citation(gemtc)
citation("gemtc")
citation("netmeta")
citation("dmetar")
citation("dmetar")
devtools::document()
devtools::load_all()
citation("dmetar")
citation(dmetar)
paste("Harrer, M., Cuijpers, P., Furukawa, T. A. & Ebert, D. D. (2019).",
"dmetar: Companion R Package For The Guide 'Doing Meta-Analysis in R'.",
"R package version 0.0.9000. URL http://dmetar.protectlab.org.")
citation("dmetar")
citation("dmetar")
citation("dmetar")
citation("dmetar")
pkgdown::build_site()
pkgdown::build_site()
pkgdown::build_site()
?direct.evidence.plot
data("NetDataNetmeta")
library(netmeta)
?netmeta
netmeta(TE, seTE, treat1, treat2,
data=NetDataNetmeta,
studlab = NetDataNetmeta$studlab)
netmeta = netmeta(TE, seTE, treat1, treat2,
data=NetDataNetmeta,
studlab = NetDataNetmeta$studlab)
nmeta = netmeta(TE, seTE, treat1, treat2,
data=NetDataNetmeta,
studlab = NetDataNetmeta$studlab)
direct.evidence.plot(nmeta)
direct.evidence.plot(nmeta)
knitr::include_graphics("fig/directevidence.png")
?sucra
data("NetDataGemtc")
# Create Network Meta-Analysis Model
network = mtc.network(data.re = NetDataGemtc)
library(gemtc)
# Create Network Meta-Analysis Model
network = mtc.network(data.re = NetDataGemtc)
model = mtc.model(network, linearModel = "fixed",
n.chain = 4,
likelihood = "normal",
link = "identity")
mcmc = mtc.run(model, n.adapt = 5000,
n.iter = 100000, thin = 10)
# Create sucra
sucra(mcmc, lower.is.better = TRUE)
sucra(mcmc, lower.is.better = TRUE)
knitr::include_graphics("fig/sucra.png")
pkgdown::build_articles()
citation("meta")
citation("metafor")
citation(netmeta)
citation("netmeta")
citation("gemtc")
pkgdown
pkgdown::build_site()
devtools::build_vignettes()
devtools::build_manual()
usethis::use_git()
usethis::use_git()
usethis::use_github()
